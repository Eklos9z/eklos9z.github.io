<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>利用hexo在github上搭建个人博客</title>
    <url>/2023/08/15/%E5%88%A9%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>由于哥们的服务器过期了，不好意思找他续费，于是决定自己搭一个blog，国内的要么广告多（X书），要么略显老旧（X园），几经挑选之后决定利用hexo在github上搭建。<br>搭建的过程基本参考了<a href="https://www.cnblogs.com/huanhao/p/hexobase.html#%E9%85%8D%E7%BD%AE%E4%B8%BB%E9%A2%98">【基础篇】hexo博客搭建教程</a>。<br>但是可能是由于版本更新的问题，遇到了一些意料之外的情况。</p>
<p>1、在git bash中执行安装cnpm出错<br>错误：Error: EPERM: operation not permitted<br>解决方案：利用管理员模式打开git即可。<br>错误：ERR! code EPERM<br>解决方案：将C：&#x2F;user&#x2F;用户名&#x2F;.npmrc删除（需要打开隐藏文件）。</p>
<p>2、上传github时页面主题未显示<br>解决方案：分别在博客页面所在的文件夹执行hexo g -d与 hexo d。（无法确认究竟是什么导致的问题）</p>
<p>3、修改schemes后上传无效<br>删除themes&#x2F;next 中的.git（隐藏），再重新执行hexo g -d与 hexo d即可</p>
<p>另：由于github的项目规则更改，如果按照链接中的教程会将页面信息上传到项目的master分支中，此时只需将页面配置文件中的branch项改成main即可。</p>
]]></content>
      <categories>
        <category>杂项比赛/学习</category>
      </categories>
      <tags>
        <tag>自学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器人比赛避障项目赛后总结</title>
    <url>/2023/08/15/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%AF%94%E8%B5%9B%E9%81%BF%E9%9A%9C%E9%A1%B9%E7%9B%AE%E8%B5%9B%E5%90%8E%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>在见到避障比赛的文件之后，对比赛算法的设计并没有我想象中那么困难：机器人直行——机器人识别到箭头——机器人向箭头指向的方向平移——机器人视野脱离箭头——机器人直行，但是直觉与经验都在告诉我这个比赛最困难的地方就是在于怎么样才能去识别到三个箭头的方向。</p>
<p>首先我通过阅读材料以及代码，很容易便对颜色识别代码进行了改写，通过改写ColorDetect.py中113行—133行，实现了识别到红色和蓝色向左平移，识别到黄色向右平移。如未识别到颜色则直行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> debug:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> __isRunning:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> detect_color != <span class="string">&#x27;None&#x27;</span>:</span><br><span class="line"></span><br><span class="line">               AGC.runActionGroup(<span class="string">&#x27;go_forward_fast&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                action_finish = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> detect_color == <span class="string">&#x27;red&#x27;</span>:</span><br><span class="line"></span><br><span class="line">AGC.runActionGroup(<span class="string">&#x27;left_move&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                    detect_color = <span class="string">&#x27;None&#x27;</span></span><br><span class="line"></span><br><span class="line">                    draw_color = range_rgb[<span class="string">&quot;black&quot;</span>]                   </span><br><span class="line"></span><br><span class="line">                    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> detect_color == <span class="string">&#x27;yellow&#x27;</span>:</span><br><span class="line"></span><br><span class="line">AGC.runActionGroup(<span class="string">&#x27;right_move&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                    detect_color = <span class="string">&#x27;None&#x27;</span></span><br><span class="line"></span><br><span class="line">                    draw_color = range_rgb[<span class="string">&quot;black&quot;</span>]                   </span><br><span class="line"></span><br><span class="line">                    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> detect_color == <span class="string">&#x27;blue&#x27;</span>:</span><br><span class="line"></span><br><span class="line">AGC.runActionGroup(<span class="string">&#x27;left_move&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                    detect_color = <span class="string">&#x27;None&#x27;</span></span><br><span class="line"></span><br><span class="line">                    draw_color = range_rgb[<span class="string">&quot;black&quot;</span>]                   </span><br><span class="line"></span><br><span class="line">                    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                    time.sleep(<span class="number">0.01</span>)               </span><br><span class="line"></span><br><span class="line">                action_finish = <span class="literal">True</span>               </span><br><span class="line"></span><br><span class="line">                detect_color = <span class="string">&#x27;None&#x27;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">               time.sleep(<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            time.sleep(<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
<p>在实际测试中发现可能由于机器人腿部舵机或是场地摩擦力问题导致机器人并不能完全的达到平移效果，经过调整，将“平移”动作后加入一个“转体”动作即可修正平移产生的过度偏差。后续的工作便是在箭头识别设计成功之后，将颜色识别替换为箭头识别即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> detect_color == <span class="string">&#x27;red&#x27;</span>:</span><br><span class="line"></span><br><span class="line">AGC.runActionGroup(<span class="string">&#x27;left_move&#x27;</span>)</span><br><span class="line"></span><br><span class="line">AGC.runActionGroup(<span class="string">&#x27;turn_left_small_step&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                    detect_color = <span class="string">&#x27;None&#x27;</span></span><br><span class="line"></span><br><span class="line">                    draw_color = range_rgb[<span class="string">&quot;black&quot;</span>]                   </span><br><span class="line"></span><br><span class="line">                    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">elif</span> detect_color == <span class="string">&#x27;yellow&#x27;</span>:</span><br><span class="line"></span><br><span class="line">AGC.runActionGroup(<span class="string">&#x27;right_move&#x27;</span>)</span><br><span class="line"></span><br><span class="line">AGC.runActionGroup(<span class="string">&#x27;turn_right_small_step&#x27;</span>)&lt;/u&gt;</span><br><span class="line"></span><br><span class="line">                    detect_color = <span class="string">&#x27;None&#x27;</span></span><br><span class="line"></span><br><span class="line">                    draw_color = range_rgb[<span class="string">&quot;black&quot;</span>]                   </span><br><span class="line"></span><br><span class="line">                    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>然后是对于箭头的识别的设计，我初步的思路是将标准箭头进行对半拆分，拆分成一个包含三角形的部分和只有矩形的部分，由于包含三角形的面积总是大于只有矩形的面积。因此可以把判断条件更改为“左右部分面积谁大”，即如果左半部分的面积更大则向左移动，右半部分的面积更大则向右移动。考虑到可能出现的图像处理问题，初步选择在lab空间中对图像进行处理。（下划线处为关键代码，下同）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> lab_data:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i != <span class="string">&#x27;black&#x27;</span> <span class="keyword">and</span> i != <span class="string">&#x27;white&#x27;</span>:</span><br><span class="line"></span><br><span class="line">                frame_mask = cv2.inRange(frame_lab,</span><br><span class="line"></span><br><span class="line">                                         (lab_data[i][<span class="string">&#x27;min&#x27;</span>][<span class="number">0</span>],</span><br><span class="line"></span><br><span class="line">                                          lab_data[i][<span class="string">&#x27;min&#x27;</span>][<span class="number">1</span>],</span><br><span class="line"></span><br><span class="line">                                          lab_data[i][<span class="string">&#x27;min&#x27;</span>][<span class="number">2</span>]),</span><br><span class="line"></span><br><span class="line">                                         (lab_data[i][<span class="string">&#x27;max&#x27;</span>][<span class="number">0</span>],</span><br><span class="line"></span><br><span class="line">                                          lab_data[i][<span class="string">&#x27;max&#x27;</span>][<span class="number">1</span>],</span><br><span class="line"></span><br><span class="line">                                          lab_data[i][<span class="string">&#x27;max&#x27;</span>][<span class="number">2</span>]))  <span class="comment">#对原图像和掩模进行位运算</span></span><br><span class="line"></span><br><span class="line">                eroded=cv2.erode(frame_mask,cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>, <span class="number">3</span>)))  <span class="comment">#腐蚀</span></span><br><span class="line"></span><br><span class="line">dilated=cv2.dilate(eroded,cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>, <span class="number">3</span>))) <span class="comment">#膨胀</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug:</span><br><span class="line"></span><br><span class="line">                cv2.imshow(i, dilated)</span><br><span class="line"></span><br><span class="line">contours=cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)[-<span class="number">2</span>]  <span class="comment">#找出轮廓</span></span><br><span class="line"></span><br><span class="line">                areaMaxContour, area_max = getAreaMaxContour(contours)  <span class="comment">#找出最大轮廓</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> areaMaxContour <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> area_max &gt; max_area:<span class="comment">#找最大面积</span></span><br><span class="line"></span><br><span class="line">                        max_area = area_max</span><br><span class="line"></span><br><span class="line">                        color_area_max = i</span><br><span class="line"></span><br><span class="line">                        areaMaxContour_max = areaMaxContour</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> max_area &gt; <span class="number">200</span>:  <span class="comment"># 有找到最大面积</span></span><br><span class="line"></span><br><span class="line">            ((centerX, centerY), radius) = cv2.minEnclosingCircle(areaMaxContour_max)  <span class="comment"># 获取最小外接圆</span></span><br><span class="line"></span><br><span class="line">            centerX = <span class="built_in">int</span>(Misc.<span class="built_in">map</span>(centerX, <span class="number">0</span>, size[<span class="number">0</span>], <span class="number">0</span>, img_w))</span><br><span class="line"></span><br><span class="line">            centerY = <span class="built_in">int</span>(Misc.<span class="built_in">map</span>(centerY, <span class="number">0</span>, size[<span class="number">1</span>], <span class="number">0</span>, img_h))</span><br><span class="line"></span><br><span class="line">            radius = <span class="built_in">int</span>(Misc.<span class="built_in">map</span>(radius, <span class="number">0</span>, size[<span class="number">0</span>], <span class="number">0</span>, img_w))      </span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>根据预设代码的研究发现，如果直接对图像进行分割，它可能会导致对最大图像的识别的误差，即在切割之后的图像可能不是识别到的最大的轮廓，如果在收集并处理过图像之后，对图像的腐蚀膨胀操作可能无法使图像正常识别，猜测因为图像经腐蚀膨胀后两边图像的差异化不够明显。故方案作废。</p>
<p>而后我通过在幻尔科技的官方网站上进行查阅资料，发现在介绍中有着“标签识别”的功能。于是我预想通过重定义标签或是对预设标签进行替换，即将两边箭头的图像编辑成“标签”，通过对新“标签”的识别做出反应，从而达到方向识别的效果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">detector = apriltag.Detector(searchpath=apriltag._get_demo_searchpath())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apriltagDetect</span>(<span class="params">img</span>):  </span><br><span class="line"></span><br><span class="line">    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">    detections = detector.detect(gray, return_image=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(detections) != <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> detection <span class="keyword">in</span> detections:                      </span><br><span class="line"></span><br><span class="line">            corners = np.rint(detection.corners)  <span class="comment"># 获取四个角点</span></span><br><span class="line"></span><br><span class="line">            cv2.drawContours(img, [np.array(corners, np.<span class="built_in">int</span>)], -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            tag_family = <span class="built_in">str</span>(detection.tag_family, encoding=<span class="string">&#x27;utf-8&#x27;</span>)  <span class="comment"># 获取tag_family</span></span><br><span class="line"></span><br><span class="line">            tag_id = <span class="built_in">int</span>(detection.tag_id)  <span class="comment"># 获取tag_id</span></span><br><span class="line"></span><br><span class="line">            object_center_x, object_center_y = <span class="built_in">int</span>(detection.center[<span class="number">0</span>]), <span class="built_in">int</span>(detection.center[<span class="number">1</span>])  <span class="comment"># 中心点</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">tag_family, tag_id = apriltagDetect(img) <span class="comment"># apriltag检测</span></span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> tag_id <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        cv2.putText(img, <span class="string">&quot;tag_id: &quot;</span> + <span class="built_in">str</span>(tag_id), (<span class="number">10</span>, img.shape[<span class="number">0</span>] - <span class="number">30</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.65</span>, [<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>], <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        cv2.putText(img, <span class="string">&quot;tag_family: &quot;</span> + tag_family, (<span class="number">10</span>, img.shape[<span class="number">0</span>] - <span class="number">10</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.65</span>, [<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>], <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        cv2.putText(img, <span class="string">&quot;tag_id: None&quot;</span>, (<span class="number">10</span>, img.shape[<span class="number">0</span>] - <span class="number">30</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.65</span>, [<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>], <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        cv2.putText(img, <span class="string">&quot;tag_family: None&quot;</span>, (<span class="number">10</span>, img.shape[<span class="number">0</span>] - <span class="number">10</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.65</span>, [<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>], <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p>经过对代码和机器人内部文件的查阅，我发现机器人的标签识别功能是建立在四个脚点的定位上，不具备对箭头等不规则图形的识别功能，同时机器人内部不存在标签相关的图像文件，难以对标签识别的代码与文件进行修改。故方案作废。</p>
<p>然后我看到了面部识别的功能介绍和代码，我计划通过修改面部识别的文件，将“箭头”作为“面部”进行识别，但经对面部识别代码以及机器人内部文件的研究，发现机器人的面部识别功能是基于.d6a模型建立起来的。无法针对已经完善的模型文件进行修改，剩余的时间也不足以训练一个新的模型，故方案作废。</p>
<p>至此，无论是剩余的时间还是任务分配都不允许我去设计其他新的思路去比赛，最终迫不得已基于思路一穷举出了可能的箭头情况并在比赛中分别调用，尽管我们及时发现并修补了机器人行动程序上的缺陷，但场地摩擦力不均带来的行动困难、机器人腿部舵机问题引起的不可控因素等场外条件将比赛算法不成熟引起的问题放大到了极致。因此很遗憾没有取得一个令人满意的成绩。</p>
]]></content>
      <categories>
        <category>杂项比赛/学习</category>
      </categories>
      <tags>
        <tag>复盘</tag>
      </tags>
  </entry>
</search>
